# ğŸ¬ Talk2Video

**Talk2Video** is an open-source AI agent that transforms spoken or written instructions into narrated videos.  
Say it â€” see it. Just like that.

Whether it's a story, presentation, tutorial, or visual script, Talk2Video listens, understands, and **directs your video with speech**.

---

## âœ¨ Features

- ğŸ™ï¸ Convert **spoken or typed commands** into full video scenes
- ğŸ§  Use **LLM (OpenAI, Mistral, etc.)** to understand and script scenes
- ğŸ“¸ Generate video scenes with **text-to-image/video models** (DALLÂ·E, SD, Pika, RunwayML)
- ğŸ—£ï¸ Add natural voiceovers with **TTS APIs** (ElevenLabs, Bark, Coqui, Google TTS)
- ğŸï¸ Compose and render final video with **FFmpeg** or **moviepy**
- ğŸ§¾ Script memory: multi-step stories or presentations
- ğŸ›ï¸ Optional GUI and CLI versions

---

## ğŸ§  Architecture & Tech Stack

| Layer | Tools |
|-------|-------|
| ğŸ—£ï¸ Input | Microphone (speech) or text prompt |
| ğŸ’¬ NLP & Scene Logic | OpenAI GPT-4, Claude, or local LLM via Ollama |
| ğŸ¨ Visual Generator | Stable Diffusion, DALLÂ·E, Pika Labs, or Runway API |
| ğŸ”Š Voice Generator | ElevenLabs, Bark, Coqui, or Google TTS |
| ğŸ¬ Video Composer | FFmpeg, moviepy, or custom compositor |
| ğŸ–¥ï¸ Interface | CLI + optional GUI (PyQt or Tauri) |
| ğŸ§° Backend | Python 3.11+ (main), Node.js (if using GUI), Shell |
| ğŸ—ƒï¸ File Format | Outputs MP4 + JSON metadata per project |

---

## ğŸ”§ Setup

```bash
git clone https://github.com/makalin/Talk2Video.git
cd Talk2Video
pip install -r requirements.txt
# Optional: setup API keys in .env
````

---

## ğŸ—£ï¸ Example Usage

### CLI

```bash
python talk2video.py --input "A calm beach at sunset, narrated in a soft female voice"
```

### Voice Mode

```bash
python talk2video.py --mic
# Speak: "Create a cyberpunk city intro with deep voice narration"
```

---

## ğŸ“¦ API Keys Required

* `OPENAI_API_KEY` â€“ for GPT logic
* `ELEVENLABS_API_KEY` (or `GOOGLE_TTS_API_KEY`) â€“ for voice
* `RUNWAY_API_KEY` or `STABLE_DIFFUSION_HOST` â€“ for visuals

---

## ğŸ”Œ Modular Design

Want to use your own models or APIs? Just replace:

* `voice.py`
* `visuals.py`
* `logic.py`

---

## ğŸ§ª Roadmap

* [ ] Scene transitions & camera effects
* [ ] Avatar lip-sync support
* [ ] Multi-language narration
* [ ] Built-in storyboarding
* [ ] Mobile app (React Native or Flutter)

---

## ğŸ¤– License

MIT License â€” free to use, modify, and contribute.

---

## ğŸ™Œ Contribute

Pull requests welcome!
Letâ€™s make storytelling with voice easy for everyone.
